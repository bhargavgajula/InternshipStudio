# -*- coding: utf-8 -*-
"""siddepatemo13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xRk3ek9eZNWLF35zzB1okC4OQMgTZWEb
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from gensim.models import Word2Vec
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

# Load your dataset
df = pd.read_csv("janaki-ram2.csv", header=0)

# Combine all text columns into a single corpus
corpus = df['industry_type'] + ' ' + df['department'] + ' ' + df['role_category'] + ' ' + df['key_skills']

unique_values_list = df['industry_type'].unique().tolist()
print(unique_values_list)
print(len(unique_values_list))

unique_values_list = df['department'].unique().tolist()
print(unique_values_list)
print(len(unique_values_list))

unique_values_list = df['role_category'].unique().tolist()
print(unique_values_list)
print(len(unique_values_list))

unique_values_list = df['key_skills'].unique().tolist()
print(unique_values_list)
print(len(unique_values_list))

unique_values_list = df['role'].unique().tolist()
print(unique_values_list)
print(len(unique_values_list))

# Tokenize the corpus
tokenized_corpus = [text.split() for text in corpus]

# Train Word2Vec model
word2vec_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)

# Function to get embeddings for a document
def get_embeddings(doc):
    return sum([word2vec_model.wv[word] for word in doc])

# Apply the function to each document in the corpus
document_embeddings = [get_embeddings(doc) for doc in tokenized_corpus]

# Add the document embeddings as new features to the DataFrame
for i in range(100):
    df[f'embedding_{i}'] = [emb[i] for emb in document_embeddings]

# Drop the original text columns
df = df.drop(['industry_type', 'department', 'role_category', 'key_skills'], axis=1)

# Separate features (X) and target variable (y)
X = df.drop('role', axis=1)
y = df['role']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Random Forest classifier
rf_model = RandomForestClassifier(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

#Evaluate model performance

# Train Accuracy
train_accuracy = accuracy_score(y_train, rf_model.predict(X_train))
print("Train Accuracy:", train_accuracy)

# Test Accuracy (already defined)
test_accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", test_accuracy)

# Precision Score
precision = precision_score(y_test, y_pred, average='weighted')  # Weighted average for multi-class problems
print("Precision Score:", precision)

# Recall Score
recall = recall_score(y_test, y_pred, average='weighted')  # Weighted average for multi-class problems
print("Recall Score:", recall)

# F1 Score
f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted average for multi-class problems
print("F1 Score:", f1)

# Evaluate model performance (e.g., using accuracy)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Visualize the distribution of predicted roles
plt.figure(figsize=(10, 6))
df['role'].value_counts().plot(kind='bar', color='skyblue', label='Actual')
pd.Series(y_pred).value_counts().plot(kind='bar', color='orange', alpha=0.7, label='Predicted')
plt.title('Distribution of Actual and Predicted Roles')
plt.xlabel('Roles')
plt.ylabel('Count')
plt.legend()
plt.show()

def preprocess_input(input_text):
    # Preprocess the input text
    tokenized_input = input_text.split()
    input_embeddings = get_embeddings(tokenized_input)
    return input_embeddings

def predict_role(input_text):
    # Preprocess input
    input_embeddings = preprocess_input(input_text)

    # Make prediction
    predicted_role = rf_model.predict([input_embeddings])
    return predicted_role[0]

# Get user input for industry type, department, role category, and key skills
industry_type = input("Enter industry type: ")
department = input("Enter department: ")
role_category = input("Enter role category: ")
key_skills = input("Enter key skills: ")

# Concatenate the inputs
user_input = industry_type + ' ' + department + ' ' + role_category + ' ' + key_skills

# Predict role
predicted_role = predict_role(user_input)
print("Predicted role:", predicted_role)